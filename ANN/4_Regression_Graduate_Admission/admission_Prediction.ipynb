{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adimission Prediction (Regression Model) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plannig before moving ahead #\n",
    "\n",
    "1) will remove unnecessary column (serial NO.)\n",
    "\n",
    "2) will scale the data. (here data is 2D so we can use StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Serial No.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          500 non-null    int64  \n",
      " 1   TOEFL Score        500 non-null    int64  \n",
      " 2   University Rating  500 non-null    int64  \n",
      " 3   SOP                500 non-null    float64\n",
      " 4   LOR                500 non-null    float64\n",
      " 5   CGPA               500 non-null    float64\n",
      " 6   Research           500 non-null    int64  \n",
      " 7   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min - Max Scaling #\n",
    "\n",
    "when we know our uper and lower boundaries we should use MIn-Max Scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled =  scaler.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Creation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation='relu',input_dim=7)) # Hidden Layer\n",
    "model.add(Dense(7,activation='relu')) # Hidden Layer\n",
    "\n",
    "# whenever we are dealing Regression problem, we must use linear regression as activation function in output Layer\n",
    "model.add(Dense(1,activation='linear'))  # Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6060 - val_loss: 0.6128\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5325 - val_loss: 0.5326\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4614 - val_loss: 0.4550\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3957 - val_loss: 0.3796\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3275 - val_loss: 0.3076\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2697 - val_loss: 0.2387\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2000 - val_loss: 0.1765\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1454 - val_loss: 0.1216\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0968 - val_loss: 0.0771\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0631 - val_loss: 0.0440\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - val_loss: 0.0225\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - val_loss: 0.0109\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "model_log = model.fit(x_train_scaled, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x31c76ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# r2_score #\n",
    "\n",
    "r2_score  = 1 means perfect predictions. Also, (closer to 1) means your model is doing a good job of predicting the data.\n",
    "\n",
    "r2_score = 0 means the model is not predicting the data at all. Also, (closer to 0) means your model is not doing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7654537992747819"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model_log.history['loss'])\n",
    "plt.plot(model_log.history['val_loss'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
